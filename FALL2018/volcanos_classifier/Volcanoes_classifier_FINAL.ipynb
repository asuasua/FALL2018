{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12092</th>\n",
       "      <th>12093</th>\n",
       "      <th>12094</th>\n",
       "      <th>12095</th>\n",
       "      <th>12096</th>\n",
       "      <th>12097</th>\n",
       "      <th>12098</th>\n",
       "      <th>12099</th>\n",
       "      <th>Volcano?</th>\n",
       "      <th>Corrupted?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "      <td>101</td>\n",
       "      <td>99</td>\n",
       "      <td>103</td>\n",
       "      <td>95</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>89</td>\n",
       "      <td>70</td>\n",
       "      <td>104</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>89</td>\n",
       "      <td>103</td>\n",
       "      <td>99</td>\n",
       "      <td>117</td>\n",
       "      <td>116</td>\n",
       "      <td>118</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>91</td>\n",
       "      <td>89</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>96</td>\n",
       "      <td>101</td>\n",
       "      <td>107</td>\n",
       "      <td>104</td>\n",
       "      <td>...</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "      <td>98</td>\n",
       "      <td>105</td>\n",
       "      <td>104</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87</td>\n",
       "      <td>70</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>93</td>\n",
       "      <td>104</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>102</td>\n",
       "      <td>94</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>80</td>\n",
       "      <td>84</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114</td>\n",
       "      <td>118</td>\n",
       "      <td>124</td>\n",
       "      <td>119</td>\n",
       "      <td>95</td>\n",
       "      <td>118</td>\n",
       "      <td>105</td>\n",
       "      <td>116</td>\n",
       "      <td>123</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>102</td>\n",
       "      <td>93</td>\n",
       "      <td>109</td>\n",
       "      <td>104</td>\n",
       "      <td>106</td>\n",
       "      <td>117</td>\n",
       "      <td>111</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79</td>\n",
       "      <td>95</td>\n",
       "      <td>90</td>\n",
       "      <td>82</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>82</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>79</td>\n",
       "      <td>78</td>\n",
       "      <td>65</td>\n",
       "      <td>71</td>\n",
       "      <td>62</td>\n",
       "      <td>97</td>\n",
       "      <td>89</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3   4    5    6    7    8    9     ...      12092  12093  \\\n",
       "0   95  101   99  103  95   86   96   89   70  104     ...         92     89   \n",
       "1   91   92   91   89  92   93   96  101  107  104     ...         93     95   \n",
       "2   87   70   72   74  84   78   93  104  106  106     ...         95    102   \n",
       "3  114  118  124  119  95  118  105  116  123  112     ...        102     93   \n",
       "4   79   95   90   82  73   74   77   75   82   87     ...         79     78   \n",
       "\n",
       "   12094  12095  12096  12097  12098  12099  Volcano?  Corrupted?  \n",
       "0    103     99    117    116    118     96         1           0  \n",
       "1     98    105    104    100     90     81         0           0  \n",
       "2     94     80     91     80     84     90         0           0  \n",
       "3    109    104    106    117    111    115         0           0  \n",
       "4     65     71     62     97     89     73         0           0  \n",
       "\n",
       "[5 rows x 12102 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### import newly, non corrupted csv\n",
    "df_clean = pd.read_csv('non_corrupted.csv').iloc[:, 1:]\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of images with volcanoes have increased to almost 23% after dropping duplicates and removing corruped images in the previous notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data for Model  Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12091</th>\n",
       "      <th>12092</th>\n",
       "      <th>12093</th>\n",
       "      <th>12094</th>\n",
       "      <th>12095</th>\n",
       "      <th>12096</th>\n",
       "      <th>12097</th>\n",
       "      <th>12098</th>\n",
       "      <th>12099</th>\n",
       "      <th>Volcano?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>87</td>\n",
       "      <td>83</td>\n",
       "      <td>87</td>\n",
       "      <td>96</td>\n",
       "      <td>89</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>92</td>\n",
       "      <td>96</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>82</td>\n",
       "      <td>92</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>86</td>\n",
       "      <td>79</td>\n",
       "      <td>66</td>\n",
       "      <td>77</td>\n",
       "      <td>69</td>\n",
       "      <td>88</td>\n",
       "      <td>106</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>81</td>\n",
       "      <td>75</td>\n",
       "      <td>82</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>68</td>\n",
       "      <td>57</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>97</td>\n",
       "      <td>104</td>\n",
       "      <td>88</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>82</td>\n",
       "      <td>88</td>\n",
       "      <td>57</td>\n",
       "      <td>86</td>\n",
       "      <td>79</td>\n",
       "      <td>71</td>\n",
       "      <td>81</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "      <td>84</td>\n",
       "      <td>74</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "      <td>91</td>\n",
       "      <td>88</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>98</td>\n",
       "      <td>97</td>\n",
       "      <td>106</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>99</td>\n",
       "      <td>108</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>93</td>\n",
       "      <td>96</td>\n",
       "      <td>108</td>\n",
       "      <td>95</td>\n",
       "      <td>100</td>\n",
       "      <td>119</td>\n",
       "      <td>112</td>\n",
       "      <td>101</td>\n",
       "      <td>92</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>64</td>\n",
       "      <td>86</td>\n",
       "      <td>72</td>\n",
       "      <td>84</td>\n",
       "      <td>88</td>\n",
       "      <td>98</td>\n",
       "      <td>77</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2    3   4    5    6    7    8   9    ...     12091  12092  \\\n",
       "0   75  97  97   95  87   83   87   96   89  76    ...        94     92   \n",
       "1   88  80  86   79  66   77   69   88  106  95    ...        89     88   \n",
       "2   74  74  68   57  77   75   97  104   88  86    ...        83     82   \n",
       "3   76  80  84   74  63   86   91   88   73  73    ...       104     98   \n",
       "4  105  93  96  108  95  100  119  112  101  92    ...        89     64   \n",
       "\n",
       "   12093  12094  12095  12096  12097  12098  12099  Volcano?  \n",
       "0     96     75     75     76     82     92     84         0  \n",
       "1     90     86     86     81     75     82     94         0  \n",
       "2     88     57     86     79     71     81     78         0  \n",
       "3     97    106    105    108     99    108     95         0  \n",
       "4     86     72     84     88     98     77     70         1  \n",
       "\n",
       "[5 rows x 12101 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Shuffle Dataframe, remove 'Corrupted?' column\n",
    "df_clean = df_clean.sample(frac=1).reset_index(drop=True).iloc[:, :-1]\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into 4 cross validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_image_set1 = np.array_split(df_clean, 4)[0].iloc[:, :-1]\n",
    "cv_label_set1 = np.array_split(df_clean, 4)[0].iloc[:, -1]\n",
    "\n",
    "cv_image_set2 = np.array_split(df_clean, 4)[1].iloc[:, :-1]\n",
    "cv_label_set2 = np.array_split(df_clean, 4)[1].iloc[:, -1]\n",
    "\n",
    "cv_image_set3 = np.array_split(df_clean, 4)[2].iloc[:, :-1]\n",
    "cv_label_set3 = np.array_split(df_clean, 4)[2].iloc[:, -1]\n",
    "\n",
    "cv_image_set4 = np.array_split(df_clean, 4)[3].iloc[:, :-1]\n",
    "cv_label_set4 = np.array_split(df_clean, 4)[3].iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1552, 12100)\n",
      "(1551, 12100)\n",
      "(1551, 12100)\n",
      "(1551, 12100)\n"
     ]
    }
   ],
   "source": [
    "### double check the dimensions of image data for initializing our models\n",
    "print(cv_image_set1.shape)\n",
    "print(cv_image_set2.shape)\n",
    "print(cv_image_set3.shape)\n",
    "print(cv_image_set4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1552,)\n",
      "(1551,)\n",
      "(1551,)\n",
      "(1551,)\n"
     ]
    }
   ],
   "source": [
    "### double check the dimensions of label data for initializing our models\n",
    "print(cv_label_set1.shape)\n",
    "print(cv_label_set2.shape)\n",
    "print(cv_label_set3.shape)\n",
    "print(cv_label_set4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Resize image data into 110x110 matrices\n",
    "cv_image_set1 = np.resize(cv_image_set1, (1552, 110, 110, 1))\n",
    "cv_image_set2 = np.resize(cv_image_set2, (1551, 110, 110, 1))\n",
    "cv_image_set3 = np.resize(cv_image_set3, (1551, 110, 110, 1))\n",
    "cv_image_set4 = np.resize(cv_image_set4, (1551, 110, 110, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize image data\n",
    "cv_image_set1 = cv_image_set1/255.0\n",
    "cv_image_set2 = cv_image_set2/255.0\n",
    "cv_image_set3 = cv_image_set3/255.0\n",
    "cv_image_set4 = cv_image_set4/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Adams model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "## Create binary categories for Labels\n",
    "cv_label_set1 = to_categorical(cv_label_set1, num_classes = 2)\n",
    "cv_label_set2 = to_categorical(cv_label_set2, num_classes = 2)\n",
    "cv_label_set3 = to_categorical(cv_label_set3, num_classes = 2)\n",
    "cv_label_set4 = to_categorical(cv_label_set4, num_classes = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "modelA = Sequential()\n",
    "modelA.add(Conv2D(filters = 8, kernel_size = (5,5), activation ='relu', input_shape = (110,110,1)))\n",
    "modelA.add(MaxPool2D(pool_size=(2,2)))\n",
    "modelA.add(Conv2D(filters = 16, kernel_size = (3,3), activation ='relu'))\n",
    "modelA.add(MaxPool2D(pool_size=(2,2)))\n",
    "modelA.add(Flatten())\n",
    "\n",
    "modelA.add(Dense(2, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 106, 106, 8)       208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 53, 53, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 51, 51, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 20002     \n",
      "=================================================================\n",
      "Total params: 21,378\n",
      "Trainable params: 21,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelA.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 1, 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sets 1, 2, 3 combined\n",
      "\n",
      "\n",
      "\n",
      "The input images have dimension(4654, 110, 110, 1)\n",
      "The test labels have dimension(4654, 2)\n",
      "Epoch 1/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5982 - acc: 0.7722\n",
      "Epoch 2/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5458 - acc: 0.7731\n",
      "Epoch 3/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5356 - acc: 0.7731\n",
      "Epoch 4/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5328 - acc: 0.7731\n",
      "Epoch 5/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5322 - acc: 0.7731\n",
      "Epoch 6/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5318 - acc: 0.7731\n",
      "Epoch 7/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5304 - acc: 0.7731\n",
      "Epoch 8/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5296 - acc: 0.7731\n",
      "Epoch 9/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5281 - acc: 0.7731\n",
      "Epoch 10/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5260 - acc: 0.7731\n",
      "Training complete\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1551/1551 [==============================] - 2s 1ms/step\n",
      "Test Loss on set 4 =  0.5354993117001655\n",
      "Test Accuracy on set 4 =  0.7666021923262561\n"
     ]
    }
   ],
   "source": [
    "### Initialize Model\n",
    "modelA = Sequential()\n",
    "modelA.add(Conv2D(filters = 8, kernel_size = (5,5), activation ='relu', input_shape = (110,110,1)))\n",
    "modelA.add(MaxPool2D(pool_size=(2,2)))\n",
    "modelA.add(Conv2D(filters = 16, kernel_size = (3,3), activation ='relu'))\n",
    "modelA.add(MaxPool2D(pool_size=(2,2)))\n",
    "modelA.add(Flatten())\n",
    "\n",
    "\n",
    "modelA.add(Dense(2, activation = \"sigmoid\"))\n",
    "\n",
    "\n",
    "modelA.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "## Combine sets 1, 2, 3\n",
    "train_123 = np.concatenate([cv_image_set1, cv_image_set2, cv_image_set3], axis=0)\n",
    "label_123 = np.concatenate([cv_label_set1, cv_label_set2, cv_label_set3], axis=0)\n",
    "print('Sets 1, 2, 3 combined\\n\\n\\n')\n",
    "\n",
    "\n",
    "print('The input images have dimension' + str(train_123.shape))\n",
    "print('The test labels have dimension' + str(label_123.shape))\n",
    "\n",
    "\n",
    "### Train\n",
    "moldelA_trained = modelA.fit(train_123, label_123, batch_size=800, epochs = 10) #validation_data=(X_val, y_val))\n",
    "print('Training complete\\n\\n\\n\\n')\n",
    "## Test on set 4\n",
    "scoreA = modelA.evaluate(cv_image_set4, cv_label_set4)\n",
    "print('Test Loss on set 4 = ', scoreA[0])\n",
    "print('Test Accuracy on set 4 = ', scoreA[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 1, 2, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sets 2, 3, 4 combined\n",
      "\n",
      "\n",
      "\n",
      "The input images have dimension(4654, 110, 110, 1)\n",
      "The test labels have dimension(4654, 2)\n",
      "Epoch 1/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5618 - acc: 0.7727\n",
      "Epoch 2/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5398 - acc: 0.7727\n",
      "Epoch 3/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5356 - acc: 0.7727\n",
      "Epoch 4/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5338 - acc: 0.7727\n",
      "Epoch 5/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5317 - acc: 0.7727\n",
      "Epoch 6/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5311 - acc: 0.7727\n",
      "Epoch 7/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5296 - acc: 0.7727\n",
      "Epoch 8/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5284 - acc: 0.7727\n",
      "Epoch 9/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5269 - acc: 0.7727\n",
      "Epoch 10/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5247 - acc: 0.7727\n",
      "Training complete\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1551/1551 [==============================] - 2s 1ms/step\n",
      "Test Loss on set 3 =  0.5293892025947571\n",
      "Test Accuracy on set 3 =  0.7678916828621595\n"
     ]
    }
   ],
   "source": [
    "### Initialize Model\n",
    "modelB = Sequential()\n",
    "modelB.add(Conv2D(filters = 8, kernel_size = (5,5), activation ='relu', input_shape = (110,110,1)))\n",
    "modelB.add(MaxPool2D(pool_size=(2,2)))\n",
    "modelB.add(Conv2D(filters = 16, kernel_size = (3,3), activation ='relu'))\n",
    "modelB.add(MaxPool2D(pool_size=(2,2)))\n",
    "modelB.add(Flatten())\n",
    "\n",
    "modelB.add(Dense(2, activation = \"sigmoid\"))\n",
    "\n",
    "\n",
    "modelB.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Combine sets 1, 2, 4\n",
    "train_124 = np.concatenate([cv_image_set1, cv_image_set2, cv_image_set4], axis=0)\n",
    "label_124 = np.concatenate([cv_label_set1, cv_label_set2, cv_label_set4], axis=0)\n",
    "print('Sets 2, 3, 4 combined\\n\\n\\n')\n",
    "\n",
    "\n",
    "print('The input images have dimension' + str(train_124.shape))\n",
    "print('The test labels have dimension' + str(label_124.shape))\n",
    "\n",
    "\n",
    "### Train on sets 1,2 4\n",
    "moldelB_trained = modelB.fit(train_124, label_124, batch_size=800, epochs = 10)\n",
    "print('Training complete\\n\\n\\n\\n')\n",
    "\n",
    "## Test on set 3\n",
    "scoreB = modelB.evaluate(cv_image_set3, cv_label_set3)\n",
    "print('Test Loss on set 3 = ', scoreB[0])\n",
    "print('Test Accuracy on set 3 = ', scoreB[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 1, 3, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sets 1, 3, 4 combined\n",
      "\n",
      "\n",
      "\n",
      "The input images have dimension(4654, 110, 110, 1)\n",
      "The test labels have dimension(4654, 2)\n",
      "Epoch 1/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5978 - acc: 0.6801\n",
      "Epoch 2/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5482 - acc: 0.7651\n",
      "Epoch 3/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5490 - acc: 0.7651\n",
      "Epoch 4/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5434 - acc: 0.7651\n",
      "Epoch 5/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5418 - acc: 0.7651\n",
      "Epoch 6/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5411 - acc: 0.7651\n",
      "Epoch 7/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5410 - acc: 0.7651\n",
      "Epoch 8/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5391 - acc: 0.7651\n",
      "Epoch 9/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5382 - acc: 0.7651\n",
      "Epoch 10/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5375 - acc: 0.7651\n",
      "Training complete\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1551/1551 [==============================] - 2s 1ms/step\n",
      "Test Loss on set 2 =  0.504737905884158\n",
      "Test Accuracy on set 2 =  0.7904577692196032\n"
     ]
    }
   ],
   "source": [
    "### Initialize Model\n",
    "modelC = Sequential()\n",
    "modelC.add(Conv2D(filters = 8, kernel_size = (5,5), activation ='relu', input_shape = (110,110,1)))\n",
    "modelC.add(MaxPool2D(pool_size=(2,2)))\n",
    "modelC.add(Conv2D(filters = 16, kernel_size = (3,3), activation ='relu'))\n",
    "modelC.add(MaxPool2D(pool_size=(2,2)))\n",
    "modelC.add(Flatten())\n",
    "\n",
    "#modelB.add(Dense(y_train.shape[1], activation = \"sigmoid\"))\n",
    "modelC.add(Dense(2, activation = \"sigmoid\"))\n",
    "\n",
    "\n",
    "modelC.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Combine sets 1, 3, 4\n",
    "train_134 = np.concatenate([cv_image_set1, cv_image_set3, cv_image_set4], axis=0)\n",
    "label_134 = np.concatenate([cv_label_set1, cv_label_set3, cv_label_set4], axis=0)\n",
    "print('Sets 1, 3, 4 combined\\n\\n\\n')\n",
    "\n",
    "\n",
    "print('The input images have dimension' + str(train_134.shape))\n",
    "print('The test labels have dimension' + str(label_134.shape))\n",
    "\n",
    "\n",
    "### Train on sets 1,2 4\n",
    "moldelC_trained = modelC.fit(train_134, label_134, batch_size=800, epochs = 10)\n",
    "print('Training complete\\n\\n\\n\\n')\n",
    "\n",
    "## Test on set 2\n",
    "scoreC = modelC.evaluate(cv_image_set2, cv_label_set2)\n",
    "print('Test Loss on set 2 = ', scoreC[0])\n",
    "print('Test Accuracy on set 2 = ', scoreC[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 2, 3, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sets 2, 3, 4 combined\n",
      "\n",
      "\n",
      "\n",
      "The input images have dimension(4653, 110, 110, 1)\n",
      "The test labels have dimension(4653, 2)\n",
      "Epoch 1/10\n",
      "4653/4653 [==============================] - 14s 3ms/step - loss: 0.5678 - acc: 0.7750\n",
      "Epoch 2/10\n",
      "4653/4653 [==============================] - 14s 3ms/step - loss: 0.5412 - acc: 0.7750\n",
      "Epoch 3/10\n",
      "4653/4653 [==============================] - 14s 3ms/step - loss: 0.5342 - acc: 0.7750\n",
      "Epoch 4/10\n",
      "4653/4653 [==============================] - 14s 3ms/step - loss: 0.5319 - acc: 0.7750\n",
      "Epoch 5/10\n",
      "4653/4653 [==============================] - 14s 3ms/step - loss: 0.5309 - acc: 0.7750\n",
      "Epoch 6/10\n",
      "4653/4653 [==============================] - 14s 3ms/step - loss: 0.5300 - acc: 0.7750\n",
      "Epoch 7/10\n",
      "4653/4653 [==============================] - 14s 3ms/step - loss: 0.5297 - acc: 0.7750\n",
      "Epoch 8/10\n",
      "4653/4653 [==============================] - 14s 3ms/step - loss: 0.5288 - acc: 0.7750\n",
      "Epoch 9/10\n",
      "4653/4653 [==============================] - 14s 3ms/step - loss: 0.5280 - acc: 0.7750\n",
      "Epoch 10/10\n",
      "4653/4653 [==============================] - 14s 3ms/step - loss: 0.5264 - acc: 0.7750\n",
      "Training complete\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1552/1552 [==============================] - 2s 1ms/step\n",
      "Test Loss on set 1 =  0.5433497988071638\n",
      "Test Accuracy on set 1 =  0.7609536082474226\n"
     ]
    }
   ],
   "source": [
    "### Initialize Model\n",
    "modelD = Sequential()\n",
    "modelD.add(Conv2D(filters = 8, kernel_size = (5,5), activation ='relu', input_shape = (110,110,1)))\n",
    "modelD.add(MaxPool2D(pool_size=(2,2)))\n",
    "modelD.add(Conv2D(filters = 16, kernel_size = (3,3), activation ='relu'))\n",
    "modelD.add(MaxPool2D(pool_size=(2,2)))\n",
    "modelD.add(Flatten())\n",
    "\n",
    "#modelB.add(Dense(y_train.shape[1], activation = \"sigmoid\"))\n",
    "modelD.add(Dense(2, activation = \"sigmoid\"))\n",
    "\n",
    "\n",
    "modelD.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Combine sets 2, 3, 4\n",
    "train_234 = np.concatenate([cv_image_set2, cv_image_set3, cv_image_set4], axis=0)\n",
    "label_234 = np.concatenate([cv_label_set2, cv_label_set3, cv_label_set4], axis=0)\n",
    "print('Sets 2, 3, 4 combined\\n\\n\\n')\n",
    "\n",
    "\n",
    "print('The input images have dimension' + str(train_234.shape))\n",
    "print('The test labels have dimension' + str(label_234.shape))\n",
    "\n",
    "\n",
    "### Train on sets 2,3, 4\n",
    "moldelD_trained = modelD.fit(train_234, label_234, batch_size=800, epochs = 10)\n",
    "print('Training complete\\n\\n\\n\\n')\n",
    "\n",
    "## Test on set 1\n",
    "scoreD = modelD.evaluate(cv_image_set1, cv_label_set1)\n",
    "print('Test Loss on set 1 = ', scoreD[0])\n",
    "print('Test Accuracy on set 1 = ', scoreD[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 1, 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sets 1, 2, 3 combined\n",
      "\n",
      "\n",
      "\n",
      "The input images have dimension(4654, 110, 110, 1)\n",
      "The test labels have dimension(4654, 2)\n",
      "Epoch 1/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5970 - acc: 0.7731\n",
      "Epoch 2/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5359 - acc: 0.7731\n",
      "Epoch 3/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5326 - acc: 0.7731\n",
      "Epoch 4/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5325 - acc: 0.7731\n",
      "Epoch 5/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5324 - acc: 0.7731\n",
      "Epoch 6/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5323 - acc: 0.7731\n",
      "Epoch 7/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5325 - acc: 0.7731\n",
      "Epoch 8/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5322 - acc: 0.7731\n",
      "Epoch 9/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5320 - acc: 0.7731\n",
      "Epoch 10/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5318 - acc: 0.7731\n",
      "Training complete\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1551/1551 [==============================] - 2s 1ms/step\n",
      "Test Loss on set 4 =  0.5413515110849028\n",
      "Test Accuracy on set 4 =  0.7666021923262561\n"
     ]
    }
   ],
   "source": [
    "### Initialize Model\n",
    "modelA = Sequential()\n",
    "modelA.add(Conv2D(filters = 8, kernel_size = (5,5), activation ='relu', input_shape = (110,110,1)))\n",
    "modelA.add(MaxPool2D(pool_size=(2,2)))\n",
    "modelA.add(Conv2D(filters = 16, kernel_size = (3,3), activation ='relu'))\n",
    "modelA.add(MaxPool2D(pool_size=(2,2)))\n",
    "modelA.add(Flatten())\n",
    "\n",
    "\n",
    "modelA.add(Dense(2, activation = \"sigmoid\"))\n",
    "\n",
    "\n",
    "modelA.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "## Combine sets 1, 2, 3\n",
    "train_123 = np.concatenate([cv_image_set1, cv_image_set2, cv_image_set3], axis=0)\n",
    "label_123 = np.concatenate([cv_label_set1, cv_label_set2, cv_label_set3], axis=0)\n",
    "print('Sets 1, 2, 3 combined\\n\\n\\n')\n",
    "\n",
    "\n",
    "print('The input images have dimension' + str(train_123.shape))\n",
    "print('The test labels have dimension' + str(label_123.shape))\n",
    "\n",
    "\n",
    "### Train\n",
    "moldelA_trained = modelA.fit(train_123, label_123, batch_size=800, epochs = 10) #validation_data=(X_val, y_val))\n",
    "print('Training complete\\n\\n\\n\\n')\n",
    "## Test on set 4\n",
    "scoreA = modelA.evaluate(cv_image_set4, cv_label_set4)\n",
    "print('Test Loss on set 4 = ', scoreA[0])\n",
    "print('Test Accuracy on set 4 = ', scoreA[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 1, 2, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sets 2, 3, 4 combined\n",
      "\n",
      "\n",
      "\n",
      "The input images have dimension(4654, 110, 110, 1)\n",
      "The test labels have dimension(4654, 2)\n",
      "Epoch 1/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.6810 - acc: 0.5868\n",
      "Epoch 2/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5959 - acc: 0.7727\n",
      "Epoch 3/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5443 - acc: 0.7727\n",
      "Epoch 4/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5347 - acc: 0.7727\n",
      "Epoch 5/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5342 - acc: 0.7727\n",
      "Epoch 6/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5341 - acc: 0.7727\n",
      "Epoch 7/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5343 - acc: 0.7727\n",
      "Epoch 8/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5340 - acc: 0.7727\n",
      "Epoch 9/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5340 - acc: 0.7727\n",
      "Epoch 10/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5338 - acc: 0.7727\n",
      "Training complete\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1551/1551 [==============================] - 2s 1ms/step\n",
      "Test Loss on set 3 =  0.5400045802714669\n",
      "Test Accuracy on set 3 =  0.7678916828621595\n"
     ]
    }
   ],
   "source": [
    "### Initialize Model\n",
    "modelB = Sequential()\n",
    "modelB.add(Conv2D(filters = 8, kernel_size = (5,5), activation ='relu', input_shape = (110,110,1)))\n",
    "modelB.add(MaxPool2D(pool_size=(2,2)))\n",
    "modelB.add(Conv2D(filters = 16, kernel_size = (3,3), activation ='relu'))\n",
    "modelB.add(MaxPool2D(pool_size=(2,2)))\n",
    "modelB.add(Flatten())\n",
    "\n",
    "\n",
    "modelB.add(Dense(2, activation = \"sigmoid\"))\n",
    "\n",
    "\n",
    "modelB.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "## Combine sets 1, 2, 4\n",
    "train_124 = np.concatenate([cv_image_set1, cv_image_set2, cv_image_set4], axis=0)\n",
    "label_124 = np.concatenate([cv_label_set1, cv_label_set2, cv_label_set4], axis=0)\n",
    "print('Sets 2, 3, 4 combined\\n\\n\\n')\n",
    "\n",
    "\n",
    "print('The input images have dimension' + str(train_124.shape))\n",
    "print('The test labels have dimension' + str(label_124.shape))\n",
    "\n",
    "\n",
    "### Train on sets 1,2 4\n",
    "moldelB_trained = modelB.fit(train_124, label_124, batch_size=800, epochs = 10)\n",
    "print('Training complete\\n\\n\\n\\n')\n",
    "\n",
    "## Test on set 3\n",
    "scoreB = modelB.evaluate(cv_image_set3, cv_label_set3)\n",
    "print('Test Loss on set 3 = ', scoreB[0])\n",
    "print('Test Accuracy on set 3 = ', scoreB[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 1, 3, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sets 1, 3, 4 combined\n",
      "\n",
      "\n",
      "\n",
      "The input images have dimension(4654, 110, 110, 1)\n",
      "The test labels have dimension(4654, 2)\n",
      "Epoch 1/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.6851 - acc: 0.5911\n",
      "Epoch 2/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.6372 - acc: 0.7651\n",
      "Epoch 3/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5848 - acc: 0.7651\n",
      "Epoch 4/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5512 - acc: 0.7651\n",
      "Epoch 5/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5435 - acc: 0.7651\n",
      "Epoch 6/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5426 - acc: 0.7651\n",
      "Epoch 7/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5425 - acc: 0.7651\n",
      "Epoch 8/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5423 - acc: 0.7651\n",
      "Epoch 9/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5423 - acc: 0.7651\n",
      "Epoch 10/10\n",
      "4654/4654 [==============================] - 14s 3ms/step - loss: 0.5422 - acc: 0.7651\n",
      "Training complete\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1551/1551 [==============================] - 2s 1ms/step\n",
      "Test Loss on set 2 =  0.5126757949379319\n",
      "Test Accuracy on set 2 =  0.7904577692196032\n"
     ]
    }
   ],
   "source": [
    "### Initialize Model\n",
    "modelC = Sequential()\n",
    "modelC.add(Conv2D(filters = 8, kernel_size = (5,5), activation ='relu', input_shape = (110,110,1)))\n",
    "modelC.add(MaxPool2D(pool_size=(2,2)))\n",
    "modelC.add(Conv2D(filters = 16, kernel_size = (3,3), activation ='relu'))\n",
    "modelC.add(MaxPool2D(pool_size=(2,2)))\n",
    "modelC.add(Flatten())\n",
    "\n",
    "\n",
    "modelC.add(Dense(2, activation = \"sigmoid\"))\n",
    "\n",
    "\n",
    "modelC.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "## Combine sets 1, 3, 4\n",
    "train_134 = np.concatenate([cv_image_set1, cv_image_set3, cv_image_set4], axis=0)\n",
    "label_134 = np.concatenate([cv_label_set1, cv_label_set3, cv_label_set4], axis=0)\n",
    "print('Sets 1, 3, 4 combined\\n\\n\\n')\n",
    "\n",
    "\n",
    "print('The input images have dimension' + str(train_134.shape))\n",
    "print('The test labels have dimension' + str(label_134.shape))\n",
    "\n",
    "\n",
    "### Train on sets 1,2 4\n",
    "moldelC_trained = modelC.fit(train_134, label_134, batch_size=800, epochs = 10)\n",
    "print('Training complete\\n\\n\\n\\n')\n",
    "\n",
    "## Test on set 2\n",
    "scoreC = modelC.evaluate(cv_image_set2, cv_label_set2)\n",
    "print('Test Loss on set 2 = ', scoreC[0])\n",
    "print('Test Accuracy on set 2 = ', scoreC[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 2, 3, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sets 2, 3, 4 combined\n",
      "\n",
      "\n",
      "\n",
      "The input images have dimension(4653, 110, 110, 1)\n",
      "The test labels have dimension(4653, 2)\n",
      "Epoch 1/10\n",
      "4653/4653 [==============================] - 14s 3ms/step - loss: 0.6014 - acc: 0.7750\n",
      "Epoch 2/10\n",
      "4653/4653 [==============================] - 14s 3ms/step - loss: 0.5363 - acc: 0.7750\n",
      "Epoch 3/10\n",
      "4653/4653 [==============================] - 14s 3ms/step - loss: 0.5328 - acc: 0.7750\n",
      "Epoch 4/10\n",
      "4653/4653 [==============================] - 14s 3ms/step - loss: 0.5326 - acc: 0.7750\n",
      "Epoch 5/10\n",
      "4653/4653 [==============================] - 14s 3ms/step - loss: 0.5323 - acc: 0.7750\n",
      "Epoch 6/10\n",
      "4653/4653 [==============================] - 14s 3ms/step - loss: 0.5322 - acc: 0.7750\n",
      "Epoch 7/10\n",
      "4653/4653 [==============================] - 14s 3ms/step - loss: 0.5322 - acc: 0.7750\n",
      "Epoch 8/10\n",
      "4653/4653 [==============================] - 14s 3ms/step - loss: 0.5322 - acc: 0.7750\n",
      "Epoch 9/10\n",
      "4653/4653 [==============================] - 14s 3ms/step - loss: 0.5319 - acc: 0.7750\n",
      "Epoch 10/10\n",
      "4653/4653 [==============================] - 14s 3ms/step - loss: 0.5318 - acc: 0.7750\n",
      "Training complete\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1552/1552 [==============================] - 2s 1ms/step\n",
      "Test Loss on set 1 =  0.546758536825475\n",
      "Test Accuracy on set 1 =  0.7609536082474226\n"
     ]
    }
   ],
   "source": [
    "### Initialize Model\n",
    "modelD = Sequential()\n",
    "modelD.add(Conv2D(filters = 8, kernel_size = (5,5), activation ='relu', input_shape = (110,110,1)))\n",
    "modelD.add(MaxPool2D(pool_size=(2,2)))\n",
    "modelD.add(Conv2D(filters = 16, kernel_size = (3,3), activation ='relu'))\n",
    "modelD.add(MaxPool2D(pool_size=(2,2)))\n",
    "modelD.add(Flatten())\n",
    "\n",
    "\n",
    "modelD.add(Dense(2, activation = \"sigmoid\"))\n",
    "\n",
    "\n",
    "modelD.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "## Combine sets 2, 3, 4\n",
    "train_234 = np.concatenate([cv_image_set2, cv_image_set3, cv_image_set4], axis=0)\n",
    "label_234 = np.concatenate([cv_label_set2, cv_label_set3, cv_label_set4], axis=0)\n",
    "print('Sets 2, 3, 4 combined\\n\\n\\n')\n",
    "\n",
    "\n",
    "print('The input images have dimension' + str(train_234.shape))\n",
    "print('The test labels have dimension' + str(label_234.shape))\n",
    "\n",
    "\n",
    "### Train on sets 2,3, 4\n",
    "moldelD_trained = modelD.fit(train_234, label_234, batch_size=800, epochs = 10)\n",
    "print('Training complete\\n\\n\\n\\n')\n",
    "\n",
    "## Test on set 1\n",
    "scoreD = modelD.evaluate(cv_image_set1, cv_label_set1)\n",
    "print('Test Loss on set 1 = ', scoreD[0])\n",
    "print('Test Accuracy on set 1 = ', scoreD[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}